摘要：
训练深度神经网络比较复杂，因为在训练过程中，每层的输入分布（distribution of inputs，指输入数值的空间分布）会由于该层的前一层的变化而改变。为此需要选择较小的学习速率并小心地选择初始化参数，而这又将导致训练效率变慢，并且众所周知的难以训练有饱和非线性函数（比如sigmod，在-1和1附件饱和）的模型。我们称该问题为内相关性变化（internal covariate shift，中文乱翻译的），并通过对每层的输入进行标准化（normalizing）解决此问题。我们方法的强处在于 1，使归一化成为模型构架的一部分；2，对每个训练最小批（trainning mini-batch）进行标准化。批标准化（Batch Normalization）允许我们使用更高的学习速率，可相对忽视初始化，并在一定程度上消除对Dropout的需求。运用到一个先进的图像分类模型上时，批标准化能在比原模型少14倍的训练次数上获得相同的精确度，并显著地打败了原模型。使用一个集成了批标准化的网络，我们使ImageNet分类的公开的最好结果显著提升：获得4.82% top-5测试错误，比人眼辨别率还高。

1. 介绍
深度学习显著地改进了视觉，语言以及许多其它领域的水平。随机梯度下降（SGD）被证明是一种有效的训练深度网络的方法，而SGD的变体如momentum和Adagrad被用来获得最先进的性能。SGD优化网络的参数Θ，并由此来最小化损失
	Θ=arg min EN[l(xi,Θ)]
	（EN表示对N个输入求均值，该公式不能理解干脆pass掉，反正我没理解，感觉也没用）
上式中x1...N是训练数据集。利用SGD，训练逐步进行，在每一步考虑一个最小批 x1...m。使用最小批的输入，和每次一输入相反，在各种方面上更有用。首先，最小批的损失梯度Em[∂l(xi,Θ)/∂Θ]是对整个训练集的梯度的估算，该估算随批大小的增加而改进。其次，在当前计算机平台上，对一个m大小的最小批的计算比对m个单独输入的计算性能更优越（应是由并行计算带来的，主要是gpu）。

随机梯度法简单而有效，但它需要小心的调整模型的超参数（hyper-parameters），特别是学习速率和初始化参数值。训练比较复杂，因为每层的输入被所有比当前层早的层的参数影响——因而，对网络参数的小小变动会随着网络变深而被放大。

层的输入分布的改变是个麻烦问题，因为该层需要持续地调整适应新的输入分布。当一个学习系统的输入分布改变，我们称其经历了相关性变化（covariate shif，乱译的）。这通常通过域适应（domain adaptation）来解决。但是，相关性变化的概念不仅作用于整个的学习系统，也作用在它的子结构上，比如一个子网络或者一个层。考虑一个网络计算：
	l=F2(F1(u,Θ1),Θ2)
F1和F2可表示任何变换，参数Θ1,Θ2是需要被学习以最小化损失l。学习Θ2参数时，可以看作以输入x=F1(u,Θ1)放入子网：
	l=F2(x,Θ2)
比如，一次梯度下降
	Θ2 ← Θ2 - αEm[∂F2(xi,∂Θ2)/∂Θ2]
(最小批大小为m，学习速率α）和一个单独的输入为x的网络F2是等价的。所以，有助于泛化网络的输入分布特性——比如对训练和测试数据有相同分布——也适用于训练子网。因此，使x的分布随着训练进行保持不变是有利的。它使Θ2不需要重新调整以抵消x的分布的改变。

对子网的输入分布的固定也对子网外的层有益。考虑一个使用sigmod激活函数 z = g(Wu + b) 的层，其中u是层输入，权重矩阵W和bias向量b是该层需要学习的参数， g(x) = 1/(1 + exp(-x))。随着|x|增加，g`(x)趋向于0。这意味着对所有尺寸的 x = Wu + b 除了那些|x|小的数，流向u的梯度将消失，对该模型的训练会缓慢。但是，由于x被W，b以及其它向后的层的参数影响，训练时对这些参数的改变很可能使x的许多维度进入非线性饱和，并减慢收敛速度。这种影响随着网络深度的增加而被放大。在实践中，这种饱和问题和由此导致的梯度消失通常使用修正线性单元ReLu(x) = max(x, 0)，小心初始化以及小的学习速率来解决。但是，如果我们能确保在训练时非线性输入的分布保持稳定，优化将不太可能被困在饱和状态中，因此训练将加快。
http://proceedings.mlr.press/v37/ioffe15.pdf